{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-12T14:34:47.670686Z",
     "iopub.status.busy": "2026-02-12T14:34:47.670431Z",
     "iopub.status.idle": "2026-02-12T14:34:49.327023Z",
     "shell.execute_reply": "2026-02-12T14:34:49.326005Z",
     "shell.execute_reply.started": "2026-02-12T14:34:47.670665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:34:52.619819Z",
     "iopub.status.busy": "2026-02-12T14:34:52.619363Z",
     "iopub.status.idle": "2026-02-12T14:34:53.295114Z",
     "shell.execute_reply": "2026-02-12T14:34:53.294292Z",
     "shell.execute_reply.started": "2026-02-12T14:34:52.619770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'clinical_doc_quality_scorer'...\n",
      "remote: Enumerating objects: 123, done.\u001b[K\n",
      "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
      "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
      "remote: Total 123 (delta 44), reused 99 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (123/123), 51.64 KiB | 1.99 MiB/s, done.\n",
      "Resolving deltas: 100% (44/44), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sl2902/clinical_doc_quality_scorer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:34:56.282105Z",
     "iopub.status.busy": "2026-02-12T14:34:56.281312Z",
     "iopub.status.idle": "2026-02-12T14:34:56.285654Z",
     "shell.execute_reply": "2026-02-12T14:34:56.284964Z",
     "shell.execute_reply.started": "2026-02-12T14:34:56.282066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/clinical_doc_quality_scorer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:35:12.255421Z",
     "iopub.status.busy": "2026-02-12T14:35:12.254767Z",
     "iopub.status.idle": "2026-02-12T14:35:24.348600Z",
     "shell.execute_reply": "2026-02-12T14:35:24.347812Z",
     "shell.execute_reply.started": "2026-02-12T14:35:12.255392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src import config\n",
    "from src.data_generation import (\n",
    "    clear_gpu_memory,\n",
    "    get_credentials,\n",
    "    load_medgemma,\n",
    "    run_scenarios,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Note: Kaggle is fickle at times. The dataset created on Kaggle sometimes appear under /kaggle/input/ or under /kaggle/input/datasets/username/; the path names could use either `_` or `-`. So list the files to get the correct path if you encounter a `File Not Found Error`\n",
    "\n",
    "Steps to run\n",
    "- Add variable `hf_token`. Click on Add-ons -> Secrets\n",
    "- Click on Save Version at the top right corner\n",
    "- Leave default version name, and ensure Version Type is Save & Run All (Commit). Click Continue\n",
    "- Check log for successful completion\n",
    "- Access the files from the Output tab. Download them, and then upload them to Kaggle as a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:55.516243Z",
     "iopub.status.busy": "2026-02-11T13:53:55.515468Z",
     "iopub.status.idle": "2026-02-11T13:55:19.172328Z",
     "shell.execute_reply": "2026-02-11T13:55:19.171624Z",
     "shell.execute_reply.started": "2026-02-11T13:53:55.516208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/medgemma-4b-it...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff57e7b602904844a72c3a91190c977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated uri note 1/10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    clear_gpu_memory()\n",
    "    # Load model once\n",
    "    tokenizer, model = load_medgemma(token=get_credentials())\n",
    "\n",
    "    run_scenarios(tokenizer, model, base_dir=\"/kaggle/input/datasets/laxmsun/prompts/\")\n",
    "\n",
    "    # run_scenarios(tokenizer, model, base_dir=\"/kaggle/input/datasets/laxmsun/prompts/\", scenarios=['uri'], n_notes_per_gender=1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9476908,
     "sourceId": 14819060,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
